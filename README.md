# <div align="center">ðŸ”¥ CORAL: Benchmarking Conversational Retrieval-Augmentation Generation<div>

We present an automatic and novel approach for constructing large-scale conversational RAG benchmarks from Wikipedia and auto-evaluation Benchmark named **CORAL**.



In CORAL, we evaluate conversational RAG systems across three essential tasks:   
(1) **Conversational Passage Retrieval**: assessing the systemâ€™s ability to retrieve relevant information from a large document set based on multi-turn context;  
(2) **Response Generation**: evaluating the systemâ€™s capacity to generate accurate, contextually rich answers;  
(3) **Citation Labeling**: ensuring that the generated responses are transparent and grounded by requiring correct attribution of sources.  



## ðŸŒ  Overview of Constructing Dataset Process
<img width="1276" alt="image" src="https://github.com/user-attachments/assets/24e33890-70b9-45de-8a98-469c8b4a97b9">
